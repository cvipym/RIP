{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ef703d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\danie/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-6-29 Python-3.7.12 torch-1.10.0+cu102 CUDA:0 (GeForce MX250, 2048MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7012822 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.321511627030717\n",
      "27.326236236888395\n",
      "27.940977796726465\n",
      "27.143733578390133\n",
      "25.021649256981274\n",
      "27.725802826584168\n",
      "27.85765332554031\n",
      "26.622895045859913\n",
      "26.219152221340117\n",
      "26.939233758309516\n",
      "26.498262638515094\n",
      "28.526664444912978\n",
      "26.268414427165858\n",
      "27.094812049017772\n",
      "26.040740809725147\n",
      "26.0849534186599\n",
      "25.128382709762455\n",
      "27.510668302057574\n",
      "28.277414091837628\n",
      "26.20555562497657\n",
      "24.48270749546163\n",
      "27.19124549438581\n",
      "26.263315424979023\n",
      "25.000023841880648\n",
      "24.590216218751465\n",
      "26.230794246404002\n",
      "26.68539726166845\n",
      "27.253791472273843\n",
      "26.099237116224657\n",
      "23.608866473786716\n",
      "25.457516220858597\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Load the YOLOv5 model with 'best.pt' weights\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='brand2_best.pt')\n",
    "\n",
    "# Set device\n",
    "#device = 'cpu'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device).eval()\n",
    "\n",
    "# Open the video file\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = video.read()\n",
    "    start_pos = time.time()\n",
    "\n",
    "    # Check if the frame was successfully read\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    # Perform inference on an image\n",
    "    results = model(frame)\n",
    "    # Access the detected objects and their labels\n",
    "    objects = results.pandas().xyxy[0]\n",
    "    # Print the detected objects and their labels\n",
    "    for i, obj in objects.iterrows():\n",
    "        class_name = obj['name']\n",
    "        confidence = obj['confidence']\n",
    "        print('Class:', class_name)\n",
    "        print('Confidence:', confidence)\n",
    "        cv2.rectangle(frame, (int(obj['xmin']), int(obj['ymin'])), (int(obj['xmax']), int(obj['ymax'])), (0, 255, 0), 2)\n",
    "        # Display the class name and confidence on the frame\n",
    "        label = f'{class_name}: {confidence:.2f}'\n",
    "        cv2.putText(frame, label, (int(obj['xmin']), int(obj['ymin']) - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Video', frame)\n",
    "        \n",
    "    time_gap = time.time() - start_pos\n",
    "    fps = 1/time_gap\n",
    "    print(fps)\n",
    "    \n",
    "    # Check for the 'q' key to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video object and close the display window\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
